# Task: Build Export Validation Framework

Priority: P0
Agent: Testing Agent
Date: 2026-01-03

## Objective

Create an automated testing system that:
1. Generates exports for 20 different configurations
2. Validates each export builds successfully
3. Compares outputs against known-good baselines
4. Reports gaps between expected and actual results

## Context

The framework generates project ZIPs based on user configuration (template + integrations).
We need to verify that every combination produces valid, buildable output.

**Test Matrix**: `output/agents/quality/workspace/export-validation-matrix.md`

## Deliverables

### 1. Test Runner Script
Location: `scripts/test-exports.ts`

```typescript
// Should support:
// - Running all 20 test configurations
// - Running specific tiers (1-4)
// - Running individual tests by ID
// - Comparing against baseline exports
// - Generating gap analysis reports
```

Features needed:
- Call `/api/export/zip` with each test configuration
- Extract ZIP to temp directory
- Run `npm install` and `npm run build`
- Validate expected files exist
- Compare file contents to baseline
- Generate summary report

### 2. Test Configuration File
Location: `scripts/test-configs/export-tests.json`

```json
{
  "tests": [
    {
      "id": "T01",
      "name": "SaaS + Supabase Auth",
      "priority": "P0",
      "config": {
        "template": "saas",
        "projectName": "test-t01",
        "integrations": { "auth": "supabase" }
      },
      "expectedFiles": [
        "lib/supabase/client.ts",
        "lib/supabase/server.ts",
        "middleware.ts"
      ],
      "expectedEnvVars": [
        "NEXT_PUBLIC_SUPABASE_URL",
        "NEXT_PUBLIC_SUPABASE_ANON_KEY"
      ]
    }
    // ... 19 more tests
  ]
}
```

### 3. Baseline Exports Directory
Location: `output/agents/quality/baseline-exports/`

For each passing test, store:
- Extracted project files
- `checksums.json` (file hashes for quick comparison)
- `test-result.json` (validation result)

### 4. Validation Utilities
Location: `scripts/lib/export-validator.ts`

Functions needed:
```typescript
// Download and extract ZIP
async function downloadExport(config: TestConfig): Promise<string>

// Validate project structure
async function validateStructure(projectPath: string, expected: string[]): Promise<ValidationResult>

// Run npm install and build
async function validateBuild(projectPath: string): Promise<BuildResult>

// Compare to baseline
async function compareToBaseline(projectPath: string, baselinePath: string): Promise<DiffResult>

// Generate report
function generateReport(results: TestResult[]): string
```

### 5. npm Scripts
Add to root `package.json`:

```json
{
  "scripts": {
    "test:exports": "tsx scripts/test-exports.ts",
    "test:exports:tier1": "tsx scripts/test-exports.ts --tier=1",
    "test:exports:quick": "tsx scripts/test-exports.ts --quick",
    "test:exports:compare": "tsx scripts/test-exports.ts --compare",
    "test:exports:baseline": "tsx scripts/test-exports.ts --update-baseline"
  }
}
```

## Validation Levels

### Level 1: Structure (Always run)
- ZIP downloads successfully
- All expected files present
- package.json valid
- .env.local.example has required vars

### Level 2: Dependencies (Always run)
- npm install succeeds
- No missing peer deps
- All integration packages present

### Level 3: Build (Always run for P0/P1)
- npm run build succeeds
- No TypeScript errors
- No import errors

### Level 4: Baseline Comparison (When --compare flag)
- File checksums match
- No unexpected new files
- No missing expected files

## Output Format

### Console Output
```
Export Validation Results
========================

Tier 1: Single Integration Tests
  ✅ T01 SaaS + Supabase Auth      [build: pass, files: 12/12]
  ✅ T02 SaaS + Clerk Auth         [build: pass, files: 8/8]
  ❌ T03 SaaS + Stripe             [build: FAIL - missing types]
  ✅ T04 SaaS + Resend             [build: pass, files: 6/6]
  ✅ T05 SaaS + PostHog            [build: pass, files: 5/5]

Tier 2: Common Combinations
  ...

Summary:
  Total: 20 | Passed: 17 | Failed: 3
  P0: 8/8 (100%) ✅
  P1: 7/9 (78%) ⚠️
  P2: 2/3 (67%) ⚠️
```

### JSON Report
Location: `output/agents/quality/workspace/export-validation-results.json`

```json
{
  "timestamp": "2026-01-03T12:00:00Z",
  "summary": {
    "total": 20,
    "passed": 17,
    "failed": 3,
    "byPriority": { "P0": { "total": 8, "passed": 8 } }
  },
  "results": [
    {
      "id": "T01",
      "name": "SaaS + Supabase Auth",
      "status": "passed",
      "duration": 12500,
      "structure": { "expected": 12, "found": 12 },
      "build": { "success": true, "duration": 8000 },
      "errors": []
    }
  ]
}
```

### Gap Analysis Report
Location: `output/agents/quality/workspace/gap-analysis.md`

Auto-generated markdown report showing:
- Which tests failed and why
- Missing files per integration
- Build errors with root causes
- Recommendations for fixes

## Success Criteria

- [ ] Test runner executes all 20 configurations
- [ ] Structure validation catches missing files
- [ ] Build validation catches compile errors
- [ ] Baseline comparison detects regressions
- [ ] Reports are clear and actionable
- [ ] P0 tests all pass before merge

## Reference Files

- Test matrix: `output/agents/quality/workspace/export-validation-matrix.md`
- Existing tests: `output/agents/quality/workspace/export-tests/`
- Existing report: `output/agents/quality/workspace/export-test-report-20260103.md`
- Export API: `website/app/api/export/zip/route.ts`
- Generator: `website/lib/generator/`

## Estimated Effort

| Component | Time |
|-----------|------|
| Test runner script | 2h |
| Test configurations | 1h |
| Validation utilities | 2h |
| Baseline system | 1h |
| npm scripts + docs | 30m |
| **Total** | ~6h |

---

*Testing Agent - Execute this task to build the validation framework*

