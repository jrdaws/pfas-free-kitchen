TASK: Build Output Quality Validation System
PRIORITY: P1 (Quality Assurance)
TYPE: Testing / Validation / Metrics
AGENT: Quality Agent

---

## Objective

Create automated systems to measure and ensure output quality,
catching issues before users see them.

## Current Problems

1. No automated testing of generated projects
2. No quality metrics for preview accuracy
3. No validation that integrations work together
4. No user feedback loop
5. No comparison to baseline "known good" outputs

## Deliverables

### 1. Export Validation Pipeline

Automated checks for every export:

```typescript
interface ValidationResult {
  structural: {
    hasPackageJson: boolean;
    hasEnvExample: boolean;
    hasReadme: boolean;
    hasAllIntegrationFiles: boolean;
  };
  buildable: {
    npmInstallSucceeds: boolean;
    npmBuildSucceeds: boolean;
    noTypeErrors: boolean;
  };
  functional: {
    envVarsDocumented: boolean;
    routesAccessible: boolean;
    componentsRender: boolean;
  };
  score: number;  // 0-100
}
```

### 2. Preview Fidelity Scoring

Measure how well preview matches export:

```typescript
interface FidelityScore {
  colorMatch: number;      // CSS variables match
  componentMatch: number;  // Same components used
  layoutMatch: number;     // Grid/flex structure
  contentMatch: number;    // Text/images
  overall: number;
}
```

Visual regression testing:
- Render preview
- Render exported project
- Compare screenshots
- Report differences

### 3. Integration Compatibility Matrix

Validate integrations work together:

```
           Supabase  Clerk  Stripe  Resend  PostHog
Supabase      -       ⚠️      ✅      ✅       ✅
Clerk        ⚠️        -      ✅      ✅       ✅
Stripe       ✅       ✅       -      ✅       ✅
```

⚠️ = Needs special handling (both provide auth)

Auto-detect conflicts and warn user.

### 4. User Feedback Collection

After export, prompt for feedback:
- "Did the project build successfully?" [Yes/No]
- "Rate the preview accuracy" [1-5 stars]
- "What was missing?" [Text]
- "Would you use this again?" [Yes/No]

Store feedback linked to configuration for analysis.

### 5. Quality Dashboard

Admin view showing:
- Export success rate over time
- Common failure points
- Integration usage stats
- User satisfaction scores
- Improvement opportunities

## Files to Create

```
scripts/
├── validate-export.ts      # CLI validation tool
├── lib/
│   ├── export-validator.ts
│   ├── fidelity-scorer.ts
│   └── compatibility-matrix.ts
└── test-configs/
    └── baseline-projects/   # Known-good exports for comparison

website/app/api/feedback/
├── export/route.ts          # Collect export feedback

website/app/admin/
└── quality-dashboard/
    └── page.tsx
```

## Success Criteria

- [ ] Validation runs on every export
- [ ] Fidelity scoring implemented
- [ ] Compatibility matrix defined
- [ ] Feedback collection live
- [ ] Quality dashboard shows metrics

## References

- Current: scripts/test-exports.ts
- Current: scripts/lib/export-validator.ts
- Current: output/agents/quality/workspace/export-validation-matrix.md

